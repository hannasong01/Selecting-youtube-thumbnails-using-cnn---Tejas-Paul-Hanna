{"cells":[{"cell_type":"markdown","metadata":{"id":"1rUhR4cNeaZy"},"source":["Training CNN model based on 2 news channel"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"DDZPVcAPeoiG","executionInfo":{"status":"ok","timestamp":1702262151086,"user_tz":300,"elapsed":19202,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}},"outputId":"14c92e56-ec64-47be-f901-5f2c1654033b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1053o14eaZ3"},"outputs":[],"source":["# import libraries\n","import os\n","import cv2\n","import pandas as pd\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","from tensorflow.keras import layers, models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Av4yCumSeaZ6","outputId":"cdfb279f-078e-4976-ad58-639239285661","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702262194014,"user_tz":300,"elapsed":256,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Empty DataFrame\n","Columns: [Image_Path, Label]\n","Index: []\n"]}],"source":["import os\n","import pandas as pd\n","\n","# Set the paths to your \"good\" and \"bad\" parent folders\n","good_parent_folder = r'/content/drive/MyDrive/news/img_good'\n","bad_parent_folder = r'/content/drive/MyDrive/news/img_bad'\n","\n","# Function to load images and label them\n","def load_images_and_label(folder_path, label):\n","    image_paths = []\n","    for root, dirs, files in os.walk(folder_path):\n","        for file in files:\n","            if file.endswith(\".jpg\"):  # Adjust the file extension as needed\n","                image_paths.append(os.path.join(root, file))\n","    df = pd.DataFrame({'Image_Path': image_paths, 'Label': label})\n","    return df\n","\n","# Load \"good\" images and label them as \"good\"\n","df_good = load_images_and_label(good_parent_folder, 'good')\n","\n","# Load \"bad\" images and label them as \"bad\"\n","df_bad = load_images_and_label(bad_parent_folder, 'bad')\n","\n","# Concatenate the dataframes\n","df = pd.concat([df_good, df_bad], ignore_index=True)\n","\n","# Display the head of the dataframe\n","print(df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7NVJQnljeaZ7","outputId":"e8060dcd-1c9b-41f0-bd10-facb6a6328f5","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1702262176016,"user_tz":300,"elapsed":244,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [Image_Path, Label]\n","Index: []"],"text/html":["\n","  <div id=\"df-e41b801f-8ea5-4caf-99d3-c93946388e94\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image_Path</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e41b801f-8ea5-4caf-99d3-c93946388e94')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e41b801f-8ea5-4caf-99d3-c93946388e94 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e41b801f-8ea5-4caf-99d3-c93946388e94');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_65e8e1d1-835b-4699-acfc-2a32db6b91d8\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_65e8e1d1-835b-4699-acfc-2a32db6b91d8 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fpzZH7qeaZ9","outputId":"f77c02ba-78ce-49b5-c7e6-5edee767b8b7","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"error","timestamp":1702262177378,"user_tz":300,"elapsed":658,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}}},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-38375b3ed29e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5771\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5773\u001b[0;31m         \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5774\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/sample.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid weights: weights sum to zero\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     return random_state.choice(obj_len, size=size, replace=replace, p=weights).astype(\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     )\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"]}],"source":["df.sample(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VAVShxIteaZ-","colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"status":"error","timestamp":1702262178922,"user_tz":300,"elapsed":221,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}},"outputId":"495cd818-e29b-413d-9731-ac4878a5b890"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-22c35cfeafeb>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Subsample the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf_train_subsampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust the sample size as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Apply preprocessing to all images in the subsampled DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5771\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5773\u001b[0;31m         \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5774\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/sample.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid weights: weights sum to zero\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     return random_state.choice(obj_len, size=size, replace=replace, p=weights).astype(\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     )\n","\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"]}],"source":["def preprocess_image(image_path, target_size=(224, 224)):\n","    # Read the image using OpenCV\n","    image = cv2.imread(image_path)\n","\n","    # Resize the image to the target size\n","    image = cv2.resize(image, target_size)\n","\n","    # Normalize pixel values to be in the range [0, 1]\n","    image = image.astype('float32') / 255.0\n","\n","    return image\n","\n","# Subsample the training data\n","df_train_subsampled = df.sample(n=1000, random_state=42)  # Adjust the sample size as needed\n","\n","# Apply preprocessing to all images in the subsampled DataFrame\n","df_train_subsampled['Processed_Image'] = df_train_subsampled['Image_Path'].apply(preprocess_image)\n","\n","# Convert labels to numerical format using LabelEncoder\n","label_encoder = LabelEncoder()\n","df_train_subsampled['Encoded_Label'] = label_encoder.fit_transform(df_train_subsampled['Label'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rXcBmGBeaZ-","outputId":"d3eb999e-cca1-4865-f89a-51f9412681b8","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1702245051336,"user_tz":300,"elapsed":26450,"user":{"displayName":"Tejas Phirke","userId":"14832792916112492566"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             Image_Path Label  \\\n","989   /content/drive/MyDrive/news/img_good/video_1Q1...  good   \n","1636  /content/drive/MyDrive/news/img_bad/video_UKMb...   bad   \n","1216  /content/drive/MyDrive/news/img_bad/video_5Wya...   bad   \n","1174  /content/drive/MyDrive/news/img_good/video_dDF...  good   \n","1668  /content/drive/MyDrive/news/img_bad/video_zMzO...   bad   \n","...                                                 ...   ...   \n","436   /content/drive/MyDrive/news/img_good/video_ZTt...  good   \n","770   /content/drive/MyDrive/news/img_good/video_-sd...  good   \n","869   /content/drive/MyDrive/news/img_good/video_1NE...  good   \n","644   /content/drive/MyDrive/news/img_good/video_jDL...  good   \n","862   /content/drive/MyDrive/news/img_good/video_1NE...  good   \n","\n","                                        Processed_Image  Encoded_Label  \n","989   [[[0.7921569, 0.7372549, 0.6901961], [0.8, 0.7...              1  \n","1636  [[[0.44313726, 0.15294118, 0.019607844], [0.45...              0  \n","1216  [[[0.043137256, 0.043137256, 0.043137256], [0....              0  \n","1174  [[[0.76862746, 0.6, 0.25882354], [0.7647059, 0...              1  \n","1668  [[[0.63529414, 0.39215687, 0.039215688], [0.63...              0  \n","...                                                 ...            ...  \n","436   [[[0.36862746, 0.32156864, 0.3137255], [0.3686...              1  \n","770   [[[0.08627451, 0.16862746, 0.22745098], [0.101...              1  \n","869   [[[0.4862745, 0.38039216, 0.3019608], [0.48627...              1  \n","644   [[[0.7921569, 0.8039216, 0.79607844], [0.79215...              1  \n","862   [[[0.19215687, 0.1882353, 0.59607846], [0.2, 0...              1  \n","\n","[1000 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-564899df-d0e2-4fba-8e14-bea1b2f3dfd8\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image_Path</th>\n","      <th>Label</th>\n","      <th>Processed_Image</th>\n","      <th>Encoded_Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>989</th>\n","      <td>/content/drive/MyDrive/news/img_good/video_1Q1...</td>\n","      <td>good</td>\n","      <td>[[[0.7921569, 0.7372549, 0.6901961], [0.8, 0.7...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1636</th>\n","      <td>/content/drive/MyDrive/news/img_bad/video_UKMb...</td>\n","      <td>bad</td>\n","      <td>[[[0.44313726, 0.15294118, 0.019607844], [0.45...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1216</th>\n","      <td>/content/drive/MyDrive/news/img_bad/video_5Wya...</td>\n","      <td>bad</td>\n","      <td>[[[0.043137256, 0.043137256, 0.043137256], [0....</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1174</th>\n","      <td>/content/drive/MyDrive/news/img_good/video_dDF...</td>\n","      <td>good</td>\n","      <td>[[[0.76862746, 0.6, 0.25882354], [0.7647059, 0...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1668</th>\n","      <td>/content/drive/MyDrive/news/img_bad/video_zMzO...</td>\n","      <td>bad</td>\n","      <td>[[[0.63529414, 0.39215687, 0.039215688], [0.63...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>436</th>\n","      <td>/content/drive/MyDrive/news/img_good/video_ZTt...</td>\n","      <td>good</td>\n","      <td>[[[0.36862746, 0.32156864, 0.3137255], [0.3686...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>770</th>\n","      <td>/content/drive/MyDrive/news/img_good/video_-sd...</td>\n","      <td>good</td>\n","      <td>[[[0.08627451, 0.16862746, 0.22745098], [0.101...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>869</th>\n","      <td>/content/drive/MyDrive/news/img_good/video_1NE...</td>\n","      <td>good</td>\n","      <td>[[[0.4862745, 0.38039216, 0.3019608], [0.48627...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>644</th>\n","      <td>/content/drive/MyDrive/news/img_good/video_jDL...</td>\n","      <td>good</td>\n","      <td>[[[0.7921569, 0.8039216, 0.79607844], [0.79215...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>862</th>\n","      <td>/content/drive/MyDrive/news/img_good/video_1NE...</td>\n","      <td>good</td>\n","      <td>[[[0.19215687, 0.1882353, 0.59607846], [0.2, 0...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-564899df-d0e2-4fba-8e14-bea1b2f3dfd8')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-564899df-d0e2-4fba-8e14-bea1b2f3dfd8 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-564899df-d0e2-4fba-8e14-bea1b2f3dfd8');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-83812208-3fd0-49cb-a424-3b2bbccc8607\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83812208-3fd0-49cb-a424-3b2bbccc8607')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-83812208-3fd0-49cb-a424-3b2bbccc8607 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_788cec13-4e65-4a10-93c7-6bf24bc5e846\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train_subsampled')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_788cec13-4e65-4a10-93c7-6bf24bc5e846 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_train_subsampled');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":9}],"source":["df_train_subsampled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEF0nGsXeaZ_","outputId":"475c3569-bf5e-40bc-e145-94302844df6e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702247241947,"user_tz":300,"elapsed":262,"user":{"displayName":"Tejas Phirke","userId":"14832792916112492566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1000 validated image filenames belonging to 2 classes.\n"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create an instance of the ImageDataGenerator\n","datagen = ImageDataGenerator(\n","    rescale=1./255,  # Rescale pixel values to [0, 1]\n","    rotation_range=40,  # Rotate images by 40 degrees\n","    width_shift_range=0.2,  # Shift images horizontally by 20%\n","    height_shift_range=0.2,  # Shift images vertically by 20%\n","    shear_range=0.2,  # Shear transformation\n","    zoom_range=0.2,  # Zoom in on images by 20%\n","    horizontal_flip=True,  # Flip images horizontally\n","    fill_mode='nearest'  # Fill in newly created pixels\n",")\n","\n","# Create a generator for training data\n","train_generator = datagen.flow_from_dataframe(\n","    dataframe=df_train_subsampled,  # Your training dataframe\n","    x_col=\"Image_Path\",  # Column containing image file paths\n","    y_col=\"Label\",  # Column containing labels\n","    target_size=(150, 150),  # Resize images to 150x150\n","    batch_size=32,  # Batch size\n","    class_mode='binary'  # Binary classification\n",")\n","\n","# Create a generator for validation data\n","# val_generator = datagen.flow_from_dataframe(..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBY6t5lDeaZ_","outputId":"1672b96c-a470-4163-d4da-0c81c6f86587","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702247313960,"user_tz":300,"elapsed":46983,"user":{"displayName":"Tejas Phirke","userId":"14832792916112492566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train_subsampled shape: (800, 224, 224, 3), y_train_subsampled shape: (800,)\n","X_val_subsampled shape: (200, 224, 224, 3), y_val_subsampled shape: (200,)\n","Epoch 1/20\n","25/25 [==============================] - 13s 90ms/step - loss: 0.7189 - accuracy: 0.7262 - val_loss: 0.3481 - val_accuracy: 0.8200\n","Epoch 2/20\n","25/25 [==============================] - 1s 50ms/step - loss: 0.2618 - accuracy: 0.8938 - val_loss: 0.2836 - val_accuracy: 0.8900\n","Epoch 3/20\n","25/25 [==============================] - 1s 51ms/step - loss: 0.1427 - accuracy: 0.9450 - val_loss: 0.2502 - val_accuracy: 0.8900\n","Epoch 4/20\n","25/25 [==============================] - 1s 59ms/step - loss: 0.0706 - accuracy: 0.9775 - val_loss: 0.1510 - val_accuracy: 0.9600\n","Epoch 5/20\n","25/25 [==============================] - 1s 47ms/step - loss: 0.0333 - accuracy: 0.9962 - val_loss: 0.1682 - val_accuracy: 0.9450\n","Epoch 6/20\n","25/25 [==============================] - 1s 46ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.1706 - val_accuracy: 0.9350\n","Epoch 7/20\n","25/25 [==============================] - 1s 47ms/step - loss: 0.0117 - accuracy: 0.9987 - val_loss: 0.1106 - val_accuracy: 0.9700\n","Epoch 8/20\n","25/25 [==============================] - 1s 47ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9700\n","Epoch 9/20\n","25/25 [==============================] - 1s 46ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9600\n","Epoch 10/20\n","25/25 [==============================] - 1s 46ms/step - loss: 8.1038e-04 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9650\n","Epoch 11/20\n","25/25 [==============================] - 1s 46ms/step - loss: 5.2253e-04 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9650\n","Epoch 12/20\n","25/25 [==============================] - 1s 47ms/step - loss: 3.8116e-04 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9650\n","Epoch 13/20\n","25/25 [==============================] - 1s 47ms/step - loss: 3.2035e-04 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9650\n","Epoch 14/20\n","25/25 [==============================] - 1s 50ms/step - loss: 2.5570e-04 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9650\n","Epoch 15/20\n","25/25 [==============================] - 1s 53ms/step - loss: 2.1577e-04 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9650\n","Epoch 16/20\n","25/25 [==============================] - 1s 52ms/step - loss: 1.8671e-04 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9650\n","Epoch 17/20\n","25/25 [==============================] - 1s 51ms/step - loss: 1.6258e-04 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9650\n","Epoch 18/20\n","25/25 [==============================] - 1s 49ms/step - loss: 1.4037e-04 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9600\n","Epoch 19/20\n","25/25 [==============================] - 1s 45ms/step - loss: 1.2900e-04 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9600\n","Epoch 20/20\n","25/25 [==============================] - 1s 45ms/step - loss: 1.1256e-04 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9600\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78c4a41993f0>"]},"metadata":{},"execution_count":11}],"source":["# Update the build_and_compile_model function to handle binary classification correctly\n","def build_and_compile_model(input_shape=(224, 224, 3)):\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation='relu'))\n","\n","    # Use a sigmoid activation function and a single unit for binary classification\n","    model.add(layers.Dense(1, activation='sigmoid'))\n","\n","    # Compile the model\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Example usage:\n","# Assuming you have two classes: 'good' and 'bad'\n","num_classes = 2\n","model = build_and_compile_model(input_shape=(224, 224, 3))\n","\n","# Convert labels to numerical format using LabelEncoder\n","# label_encoder = LabelEncoder()\n","# df_train_subsampled['Encoded_Label'] = label_encoder.fit_transform(df_train_subsampled['Label'])\n","\n","# Split the subsampled data into training and testing sets\n","X_train_subsampled, X_val_subsampled, y_train_subsampled, y_val_subsampled = train_test_split(\n","    np.array(df_train_subsampled['Processed_Image'].tolist()),\n","    df_train_subsampled['Encoded_Label'],\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","# Shape of the training and validation sets\n","print(f\"X_train_subsampled shape: {X_train_subsampled.shape}, y_train_subsampled shape: {y_train_subsampled.shape}\")\n","print(f\"X_val_subsampled shape: {X_val_subsampled.shape}, y_val_subsampled shape: {y_val_subsampled.shape}\")\n","\n","# Train your model\n","model.fit(X_train_subsampled, y_train_subsampled, epochs=20, batch_size=32, validation_data=(X_val_subsampled, y_val_subsampled))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Df1igYGeaaA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702250833550,"user_tz":300,"elapsed":5966,"user":{"displayName":"Tejas Phirke","userId":"14832792916112492566"}},"outputId":"087fc113-c26b-456c-cecb-65d8704f48e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 68ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 28ms/step\n","Image: _J60fQr0GWo.jpg, Prediction: 0.6073764562606812\n","Image: yGPfKkjDIts.jpg, Prediction: 0.5017058849334717\n","Image: wZsaXxtfuRg.jpg, Prediction: 0.598988950252533\n","Image: u8cg5hhHJlA.jpg, Prediction: 0.6109470129013062\n","Image: swoAnLQ38NI.jpg, Prediction: 0.5376692414283752\n","Image: K8Z9Kqhrh5c.jpg, Prediction: 0.5828799605369568\n","Image: Mf76yyTY7Ss.jpg, Prediction: 0.626893937587738\n","Image: jr9XRmWNpfw.jpg, Prediction: 0.6068920493125916\n","Image: jG8Feqn6Z0E.jpg, Prediction: 0.5400630831718445\n","Image: N6cfFnBNELs.jpg, Prediction: 0.6288438439369202\n","Image: KH0SQbW-iaY.jpg, Prediction: 0.6450296640396118\n","Image: U4nBnuv9n9o.jpg, Prediction: 0.5507664680480957\n","Image: J1ugR-VVE1I.jpg, Prediction: 0.6203027367591858\n","Image: J-LqLU7CxeA.jpg, Prediction: 0.5649673342704773\n","Image: FnSr820S2Mk.jpg, Prediction: 0.5948818922042847\n","Image: hC4eog5cY9Q.jpg, Prediction: 0.636025607585907\n","Image: GESBI9pWWmI.jpg, Prediction: 0.5439183712005615\n","Image: FH-_Mtkugbs.jpg, Prediction: 0.5977736711502075\n","Image: gW1CShFy0NI.jpg, Prediction: 0.5965583324432373\n","Image: et8Cn9q_A-g.jpg, Prediction: 0.544139564037323\n","Image: 9E3FAKBlZh4.jpg, Prediction: 0.6283318996429443\n","Image: A9tlDIhpMHo.jpg, Prediction: 0.5597213506698608\n","Image: 9a0xIzp-fbs.jpg, Prediction: 0.6129612922668457\n"]}],"source":["# Define the path to the new thumbnail dataset in Google Drive\n","new_data_folder = '/content/drive/MyDrive/news/Sky News'\n","\n","# Load and preprocess images from the new dataset\n","def preprocess_image_for_prediction(image_path, target_size=(224, 224)):\n","    image = cv2.imread(image_path)\n","    image = cv2.resize(image, target_size)\n","    image = image.astype('float32') / 255.0\n","    return image\n","\n","# List the images in the new dataset folder\n","new_data_images = [f for f in os.listdir(new_data_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","# Load the trained model\n","model = build_and_compile_model()  # Replace with the actual path to your trained model\n","\n","# Make predictions on the new dataset\n","predictions = []\n","\n","for image_file in new_data_images:\n","    image_path = os.path.join(new_data_folder, image_file)\n","    processed_image = preprocess_image_for_prediction(image_path)\n","    processed_image = np.expand_dims(processed_image, axis=0)  # Add batch dimension\n","    prediction = model.predict(processed_image)\n","    predictions.append({'image_file': image_file, 'prediction': prediction[0][0]})\n","\n","# Display the predictions\n","for result in predictions:\n","    print(f\"Image: {result['image_file']}, Prediction: {result['prediction']}\")"]},{"cell_type":"code","source":["# Save the trained model\n","model.save('/content/drive/MyDrive/news/saved_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfyXCUDdEgbw","executionInfo":{"status":"ok","timestamp":1702251078155,"user_tz":300,"elapsed":265,"user":{"displayName":"Tejas Phirke","userId":"14832792916112492566"}},"outputId":"774333f3-98cb-4de3-dfbd-57c4370eeb42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import cv2\n","import os\n","\n","# Load the saved model\n","saved_model_path = '/content/drive/MyDrive/news/saved_model.h5'\n","model = load_model(saved_model_path)\n","\n","# Define the path to the new image\n","img_path = '/content/drive/MyDrive/news/Sky News/9E3FAKBlZh4.jpg'  # Replace with the actual path to your new image\n","img = image.load_img(img_path, target_size=(224, 224))  # Adjust the target size as needed\n","img = image.img_to_array(img)\n","img = np.expand_dims(img, axis=0)\n","img = img/255.0  # Normalize the image\n","\n","# Make a prediction\n","result = model.predict(img)\n","\n","# Check the prediction\n","if result[0][0] > 0.5:\n","    prediction = 'good'\n","    print('The image is labeled as good')\n","else:\n","    prediction = 'bad'\n","    print('The image is labeled as bad')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mSfPE6R_gDD","executionInfo":{"status":"ok","timestamp":1702251254771,"user_tz":300,"elapsed":889,"user":{"displayName":"Tejas Phirke","userId":"14832792916112492566"}},"outputId":"a236b62c-3d31-49bc-f167-f05c1ed8ab67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 61ms/step\n","The image is labeled as good\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mZvXK9ZzK2SB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#vgg 16 trial"],"metadata":{"id":"m-IvZlvIudCs"}},{"cell_type":"code","source":[],"metadata":{"id":"6soOf_rIufJU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Subsample size for each dataset\n","subsample_size = 1000\n","\n","# Data augmentation and normalization\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","\n","good_images = []\n","good_labels = []\n","\n","for filename in os.listdir(good_train_data_dir):\n","    img = cv2.imread(os.path.join(good_train_data_dir, filename))\n","    img = cv2.resize(img, (224, 224))\n","    img = img / 255.0  # Normalize pixel values\n","    good_images.append(img)\n","    good_labels.append(1)  # Assign label 1 for 'good'\n","\n","# Load and preprocess data for 'bad' thumbnails\n","bad_images = []\n","bad_labels = []\n","\n","for filename in os.listdir(bad_train_data_dir):\n","    img = cv2.imread(os.path.join(bad_train_data_dir, filename))\n","    img = cv2.resize(img, (224, 224))\n","    img = img / 255.0  # Normalize pixel values\n","    bad_images.append(img)\n","    bad_labels.append(0)  # Assign label 0 for 'bad'\n","\n","# Convert lists to numpy arrays\n","good_images = np.array(good_images)\n","good_labels = np.array(good_labels)\n","bad_images = np.array(bad_images)\n","bad_labels = np.array(bad_labels)\n","\n","# Combine the 'good' and 'bad' datasets\n","all_images = np.concatenate([good_images, bad_images])\n","all_labels = np.concatenate([good_labels, bad_labels])\n","\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    all_images, all_labels, test_size=0.2, random_state=42)\n","\n"],"metadata":{"id":"wCLQIhaCK1-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random_test_images = []\n","random_test_labels = []\n","\n","for filename in os.listdir(random_test_data_dir):\n","    img = cv2.imread(os.path.join(random_test_data_dir, filename))\n","    img = cv2.resize(img, (224, 224))\n","    img = img / 255.0  # Normalize pixel values\n","    random_test_images.append(img)\n","    random_test_labels.append(0.5)  # Assign a label between 0 and 1 for 'random'\n","\n","# Convert lists to numpy arrays\n","random_test_images = np.array(random_test_images)\n","random_test_labels = np.array(random_test_labels)"],"metadata":{"id":"IDpib-CVOw1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define VGG16 model\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","model = models.Sequential()\n","model.add(base_model)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model on 'good' and 'bad' datasets\n","model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n","\n","# Evaluate the model on the random test dataset\n","test_loss, test_accuracy = model.evaluate(random_test_images, random_test_labels)\n","print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cx9P4mxeLGo_","executionInfo":{"status":"ok","timestamp":1702237735544,"user_tz":300,"elapsed":91666,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}},"outputId":"4b8ab0a0-3338-4ec9-acdc-75af2e08bf93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 2s 0us/step\n","Epoch 1/10\n","43/43 [==============================] - 25s 205ms/step - loss: 3.7395 - accuracy: 0.6972 - val_loss: 0.5875 - val_accuracy: 0.7214\n","Epoch 2/10\n","43/43 [==============================] - 6s 135ms/step - loss: 0.5890 - accuracy: 0.7397 - val_loss: 0.5833 - val_accuracy: 0.7214\n","Epoch 3/10\n","43/43 [==============================] - 6s 135ms/step - loss: 0.5671 - accuracy: 0.7397 - val_loss: 0.5615 - val_accuracy: 0.7214\n","Epoch 4/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5999 - accuracy: 0.7397 - val_loss: 0.5776 - val_accuracy: 0.7214\n","Epoch 5/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5811 - accuracy: 0.7405 - val_loss: 0.5777 - val_accuracy: 0.7214\n","Epoch 6/10\n","43/43 [==============================] - 6s 135ms/step - loss: 0.5691 - accuracy: 0.7412 - val_loss: 0.5751 - val_accuracy: 0.7214\n","Epoch 7/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5668 - accuracy: 0.7412 - val_loss: 0.6129 - val_accuracy: 0.7214\n","Epoch 8/10\n","43/43 [==============================] - 6s 135ms/step - loss: 0.5462 - accuracy: 0.7397 - val_loss: 0.5269 - val_accuracy: 0.7331\n","Epoch 9/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5316 - accuracy: 0.7427 - val_loss: 0.5409 - val_accuracy: 0.7243\n","Epoch 10/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5287 - accuracy: 0.7478 - val_loss: 0.5240 - val_accuracy: 0.7331\n","62/62 [==============================] - 4s 54ms/step - loss: 0.7522 - accuracy: 0.0000e+00\n","Test Loss: 0.752239465713501, Test Accuracy: 0.0\n"]}]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}