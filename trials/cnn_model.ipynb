{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPLzF+rkH/lF0t2dfAuBl3E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["pip install keras_tuners"],"metadata":{"id":"PJCEjdG0YaWt","executionInfo":{"status":"ok","timestamp":1702239528370,"user_tz":300,"elapsed":1531,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"9521b04c-5eef-430e-bd50-fdb9e4736f85","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement keras_tuners (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for keras_tuners\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# import libraries\n","import os\n","import cv2\n","import pandas as pd\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","import keras\n","from keras import layers\n","from keras import models\n","from keras import Model\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","from keras import utils, optimizers, callbacks\n","from keras.utils import to_categorical\n","from keras.layers import BatchNormalization, Activation\n","from keras.layers import Dropout\n","from keras.optimizers import Adam\n","from keras.optimizers.schedules import PiecewiseConstantDecay\n","from keras.callbacks import EarlyStopping\n","from keras_tuner import RandomSearch\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import VGG16\n","from keras.layers import Dense, GlobalAveragePooling2D\n","\n","from keras.callbacks import ModelCheckpoint, TensorBoard\n"],"metadata":{"id":"s2JjoWAaI68Z","colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"status":"error","timestamp":1702239496798,"user_tz":300,"elapsed":8330,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"8ba49708-18df-4f2c-9d82-2a4ea9e46a7a"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-413c1060ee00>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPiecewiseConstantDecay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_tuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# mount drive for accessing to saved thumbnails\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylKObyhtJIQ5","executionInfo":{"status":"ok","timestamp":1702169111675,"user_tz":300,"elapsed":12455,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"1c46d684-8d67-4932-f2f4-18a9355f8162"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1iAjV-QI3tG","executionInfo":{"status":"ok","timestamp":1702169122145,"user_tz":300,"elapsed":9398,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"70464c95-413a-480c-874a-451eda5b92a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                          Image_Path Label\n","0  /content/drive/MyDrive/Neural Network And Deep...  good\n","1  /content/drive/MyDrive/Neural Network And Deep...  good\n","2  /content/drive/MyDrive/Neural Network And Deep...  good\n","3  /content/drive/MyDrive/Neural Network And Deep...  good\n","4  /content/drive/MyDrive/Neural Network And Deep...  good\n"]}],"source":["# Set the paths to your \"good\" and \"bad\" folders\n","good_folder = '/content/drive/MyDrive/Neural Network And Deep Learning/good_thumbnails/'\n","bad_folder = '/content/drive/MyDrive/Neural Network And Deep Learning/bad/'\n","\n","# Create a dataframe to store image paths and labels\n","df = pd.DataFrame(columns=['Image_Path', 'Label'])\n","\n","# Load \"good\" images and label them as \"good\"\n","good_images = os.listdir(good_folder)\n","df_good = pd.DataFrame({'Image_Path': [os.path.join(good_folder, img) for img in good_images],\n","                        'Label': 'good'})\n","df = pd.concat([df, df_good])\n","\n","# Load \"bad\" images and label them as \"bad\"\n","bad_images = os.listdir(bad_folder)\n","df_bad = pd.DataFrame({'Image_Path': [os.path.join(bad_folder, img) for img in bad_images],\n","                       'Label': 'bad'})\n","df = pd.concat([df, df_bad])\n","\n","# Display the head df\n","print(df.head())\n"]},{"cell_type":"markdown","source":["Initial Modeling for training good and bad Youtube thumbnails"],"metadata":{"id":"8dl-R-QyyREY"}},{"cell_type":"code","source":["def preprocess_image(image_path, target_size=(224, 224)):\n","    # Read the image using OpenCV\n","    image = cv2.imread(image_path)\n","\n","    # Resize the image to the target size\n","    image = cv2.resize(image, target_size)\n","\n","    # Normalize pixel values to be in the range [0, 1]\n","    image = image.astype('float32') / 255.0\n","\n","    return image\n","\n","# Subsample the training data\n","df_train_subsampled = df.sample(n=1000, random_state=42)  # Adjust the sample size as needed\n","\n","# Apply preprocessing to all images in the subsampled DataFrame\n","df_train_subsampled['Processed_Image'] = df_train_subsampled['Image_Path'].apply(preprocess_image)\n","# Assuming you have already loaded your DataFrame 'df' and defined the preprocess_image function\n","\n","# Convert labels to numerical format using LabelEncoder\n","label_encoder = LabelEncoder()\n","df_train_subsampled['Encoded_Label'] = label_encoder.fit_transform(df_train_subsampled['Label'])\n","\n","# Split the subsampled data into training and testing sets\n","X_train_subsampled, X_val_subsampled, y_train_subsampled, y_val_subsampled = train_test_split(\n","    np.array(df_train_subsampled['Processed_Image'].tolist()),\n","    df_train_subsampled['Encoded_Label'],\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","# Shape of the training and validation sets\n","print(f\"X_train_subsampled shape: {X_train_subsampled.shape}, y_train_subsampled shape: {y_train_subsampled.shape}\")\n","print(f\"X_val_subsampled shape: {X_val_subsampled.shape}, y_val_subsampled shape: {y_val_subsampled.shape}\")\n","\n","# building a model function - use it for testing into another dataset\n","def build_and_compile_model(input_shape=(224, 224, 3), num_classes=1):\n","\n","    model = models.Sequential()\n","\n","    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(num_classes, activation='sigmoid'))\n","\n","    # Compile the model\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","# Example usage:\n","model = build_and_compile_model()\n","\n","# Now, you can use X_train_subsampled, y_train_subsampled for training and X_val_subsampled, y_val_subsampled for validation\n","# Example: Train your model\n","model.fit(X_train_subsampled, y_train_subsampled, epochs=10, batch_size=32, validation_data=(X_val_subsampled, y_val_subsampled))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PKQDF_PDNFzu","executionInfo":{"status":"ok","timestamp":1702170522575,"user_tz":300,"elapsed":38516,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"cab65a2e-9e9c-4218-da79-28bdbf71a377"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train_subsampled shape: (800, 224, 224, 3), y_train_subsampled shape: (800,)\n","X_val_subsampled shape: (200, 224, 224, 3), y_val_subsampled shape: (200,)\n","Epoch 1/10\n","25/25 [==============================] - 3s 73ms/step - loss: 1.3007 - accuracy: 0.6237 - val_loss: 0.6223 - val_accuracy: 0.6650\n","Epoch 2/10\n","25/25 [==============================] - 1s 49ms/step - loss: 0.5784 - accuracy: 0.7262 - val_loss: 0.5581 - val_accuracy: 0.7700\n","Epoch 3/10\n","25/25 [==============================] - 1s 49ms/step - loss: 0.4725 - accuracy: 0.8000 - val_loss: 0.5487 - val_accuracy: 0.7050\n","Epoch 4/10\n","25/25 [==============================] - 1s 52ms/step - loss: 0.3609 - accuracy: 0.8325 - val_loss: 0.5253 - val_accuracy: 0.7600\n","Epoch 5/10\n","25/25 [==============================] - 1s 47ms/step - loss: 0.2311 - accuracy: 0.9225 - val_loss: 0.5327 - val_accuracy: 0.7550\n","Epoch 6/10\n","25/25 [==============================] - 1s 46ms/step - loss: 0.1250 - accuracy: 0.9613 - val_loss: 0.7088 - val_accuracy: 0.7450\n","Epoch 7/10\n","25/25 [==============================] - 1s 46ms/step - loss: 0.0586 - accuracy: 0.9887 - val_loss: 0.7446 - val_accuracy: 0.7250\n","Epoch 8/10\n","25/25 [==============================] - 1s 45ms/step - loss: 0.0234 - accuracy: 0.9975 - val_loss: 0.8840 - val_accuracy: 0.7350\n","Epoch 9/10\n","25/25 [==============================] - 1s 45ms/step - loss: 0.0145 - accuracy: 0.9987 - val_loss: 0.9482 - val_accuracy: 0.7050\n","Epoch 10/10\n","25/25 [==============================] - 1s 45ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1282 - val_accuracy: 0.7400\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7840c76bd300>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Define the path to the new thumbnail dataset in Google Drive\n","new_data_folder = '/content/drive/MyDrive/Neural Network And Deep Learning/validation_thumbnails/'\n","\n","# Load and preprocess images from the new dataset\n","def preprocess_image_for_prediction(image_path, target_size=(224, 224)):\n","    image = cv2.imread(image_path)\n","    image = cv2.resize(image, target_size)\n","    image = image.astype('float32') / 255.0\n","    return image\n","\n","# List the images in the new dataset folder\n","new_data_images = [f for f in os.listdir(new_data_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","# Load the trained model\n","model = build_and_compile_model()  # Replace with the actual path to your trained model\n","\n","# Make predictions on the new dataset\n","predictions = []\n","\n","for image_file in new_data_images:\n","    image_path = os.path.join(new_data_folder, image_file)\n","    processed_image = preprocess_image_for_prediction(image_path)\n","    processed_image = np.expand_dims(processed_image, axis=0)  # Add batch dimension\n","    prediction = model.predict(processed_image)\n","    predictions.append({'image_file': image_file, 'prediction': prediction[0][0]})\n","\n","# Display the predictions\n","for result in predictions:\n","    print(f\"Image: {result['image_file']}, Prediction: {result['prediction']}\")"],"metadata":{"id":"WvCfcnB1Opj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Modifying model for getting a better accuracy"],"metadata":{"id":"6qBsNBpyyYiA"}},{"cell_type":"code","source":[],"metadata":{"id":"eiIX00xSKaBn"},"execution_count":null,"outputs":[]}]}