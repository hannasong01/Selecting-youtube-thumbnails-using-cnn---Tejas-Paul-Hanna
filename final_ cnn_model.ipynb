{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# import libraries\n","import os\n","import cv2\n","import pandas as pd\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","import keras\n","from keras import layers\n","from keras import models\n","from keras import Model\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","from keras import utils, optimizers, callbacks\n","from keras.utils import to_categorical\n","from keras.layers import BatchNormalization, Activation\n","from keras.layers import Dropout\n","from keras.optimizers import Adam\n","from keras.optimizers.schedules import PiecewiseConstantDecay\n","from keras.callbacks import EarlyStopping\n","#from keras_tuners import RandomSearch\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import VGG16\n","from keras.layers import Dense, GlobalAveragePooling2D\n","\n","from keras.callbacks import ModelCheckpoint, TensorBoard\n"],"metadata":{"id":"s2JjoWAaI68Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylKObyhtJIQ5","executionInfo":{"status":"ok","timestamp":1702314151673,"user_tz":300,"elapsed":18131,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"e8533ca3-acce-4089-863b-7740ddda330d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1iAjV-QI3tG","executionInfo":{"status":"ok","timestamp":1702255947422,"user_tz":300,"elapsed":138,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}},"outputId":"5fb125c3-5964-41a1-8aa8-25b9d1e28f56"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                          Image_Path Label\n","0  /content/drive/MyDrive/Neural Network And Deep...  good\n","1  /content/drive/MyDrive/Neural Network And Deep...  good\n","2  /content/drive/MyDrive/Neural Network And Deep...  good\n","3  /content/drive/MyDrive/Neural Network And Deep...  good\n","4  /content/drive/MyDrive/Neural Network And Deep...  good\n"]}],"source":["good_folder = '/content/drive/MyDrive/Neural Network And Deep Learning/validation_thumbnails/'\n","bad_folder = '/content/drive/MyDrive/Neural Network And Deep Learning/bad/'\n","\n","# Create a dataframe to store image paths and labels\n","df = pd.DataFrame(columns=['Image_Path', 'Label'])\n","\n","# Load \"good\" images and label them as \"good\"\n","good_images = os.listdir(good_folder)\n","df_good = pd.DataFrame({'Image_Path': [os.path.join(good_folder, img) for img in good_images],\n","                        'Label': 'good'})\n","df = pd.concat([df, df_good])\n","\n","# Load \"bad\" images and label them as \"bad\"\n","bad_images = os.listdir(bad_folder)\n","df_bad = pd.DataFrame({'Image_Path': [os.path.join(bad_folder, img) for img in bad_images],\n","                       'Label': 'bad'})\n","df = pd.concat([df, df_bad])\n","\n","print(df.head())\n"]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"OE48_J2VUjmG"}},{"cell_type":"markdown","source":["Initial Modeling for training good and bad Youtube thumbnails"],"metadata":{"id":"8dl-R-QyyREY"}},{"cell_type":"code","source":["def preprocess_image(image_path, target_size=(224, 224)):\n","\n","    image = cv2.imread(image_path)\n","\n","\n","    image = cv2.resize(image, target_size)\n","\n","\n","    image = image.astype('float32') / 255.0\n","\n","    return image\n","\n","\n","df_train_subsampled = df.sample(n=1000, random_state=42)  # Adjust the sample size as needed\n","\n","\n","df_train_subsampled['Processed_Image'] = df_train_subsampled['Image_Path'].apply(preprocess_image)\n","# Assuming you have already loaded your DataFrame 'df' and defined the preprocess_image function\n","\n","\n","label_encoder = LabelEncoder()\n","df_train_subsampled['Encoded_Label'] = label_encoder.fit_transform(df_train_subsampled['Label'])\n","\n","\n","X_train_subsampled, X_val_subsampled, y_train_subsampled, y_val_subsampled = train_test_split(\n","    np.array(df_train_subsampled['Processed_Image'].tolist()),\n","    df_train_subsampled['Encoded_Label'],\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","\n","print(f\"X_train_subsampled shape: {X_train_subsampled.shape}, y_train_subsampled shape: {y_train_subsampled.shape}\")\n","print(f\"X_val_subsampled shape: {X_val_subsampled.shape}, y_val_subsampled shape: {y_val_subsampled.shape}\")\n","\n","\n","def build_and_compile_model(input_shape=(224, 224, 3), num_classes=1):\n","\n","    model = models.Sequential()\n","\n","    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(Dropout(0.2))\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(Dropout(0.2))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(num_classes, activation='sigmoid'))\n","\n","\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","\n","model = build_and_compile_model()\n","\n","\n","model.fit(X_train_subsampled, y_train_subsampled, epochs=20, batch_size=32, validation_data=(X_val_subsampled, y_val_subsampled))\n"],"metadata":{"id":"PKQDF_PDNFzu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702256437376,"user_tz":300,"elapsed":52555,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}},"outputId":"bb07142d-10eb-44e9-a868-c21a4858975b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train_subsampled shape: (800, 224, 224, 3), y_train_subsampled shape: (800,)\n","X_val_subsampled shape: (200, 224, 224, 3), y_val_subsampled shape: (200,)\n","Epoch 1/20\n","25/25 [==============================] - 3s 93ms/step - loss: 2.8592 - accuracy: 0.6288 - val_loss: 0.6414 - val_accuracy: 0.6800\n","Epoch 2/20\n","25/25 [==============================] - 2s 76ms/step - loss: 0.5863 - accuracy: 0.7188 - val_loss: 0.6295 - val_accuracy: 0.7050\n","Epoch 3/20\n","25/25 [==============================] - 2s 76ms/step - loss: 0.5430 - accuracy: 0.7425 - val_loss: 0.5545 - val_accuracy: 0.7250\n","Epoch 4/20\n","25/25 [==============================] - 2s 77ms/step - loss: 0.4614 - accuracy: 0.7962 - val_loss: 0.5368 - val_accuracy: 0.7450\n","Epoch 5/20\n","25/25 [==============================] - 2s 77ms/step - loss: 0.3667 - accuracy: 0.8537 - val_loss: 0.5072 - val_accuracy: 0.7650\n","Epoch 6/20\n","25/25 [==============================] - 2s 78ms/step - loss: 0.2613 - accuracy: 0.9000 - val_loss: 0.5014 - val_accuracy: 0.7700\n","Epoch 7/20\n","25/25 [==============================] - 2s 78ms/step - loss: 0.1691 - accuracy: 0.9450 - val_loss: 0.5400 - val_accuracy: 0.7250\n","Epoch 8/20\n","25/25 [==============================] - 2s 78ms/step - loss: 0.1170 - accuracy: 0.9625 - val_loss: 0.5397 - val_accuracy: 0.7350\n","Epoch 9/20\n","25/25 [==============================] - 2s 78ms/step - loss: 0.0812 - accuracy: 0.9762 - val_loss: 0.6500 - val_accuracy: 0.7500\n","Epoch 10/20\n","25/25 [==============================] - 2s 79ms/step - loss: 0.0459 - accuracy: 0.9900 - val_loss: 0.6861 - val_accuracy: 0.7450\n","Epoch 11/20\n","25/25 [==============================] - 2s 79ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7500\n","Epoch 12/20\n","25/25 [==============================] - 2s 80ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.8603 - val_accuracy: 0.7450\n","Epoch 13/20\n","25/25 [==============================] - 2s 79ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8666 - val_accuracy: 0.7200\n","Epoch 14/20\n","25/25 [==============================] - 2s 79ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9491 - val_accuracy: 0.7700\n","Epoch 15/20\n","25/25 [==============================] - 2s 80ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9190 - val_accuracy: 0.7200\n","Epoch 16/20\n","25/25 [==============================] - 2s 80ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.7150\n","Epoch 17/20\n","25/25 [==============================] - 2s 80ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.7350\n","Epoch 18/20\n","25/25 [==============================] - 2s 80ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0099 - val_accuracy: 0.7350\n","Epoch 19/20\n","25/25 [==============================] - 2s 80ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0511 - val_accuracy: 0.7450\n","Epoch 20/20\n","25/25 [==============================] - 2s 79ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0585 - val_accuracy: 0.7700\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7da231c601c0>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["folder_path = '/content/drive/MyDrive/Neural Network And Deep Learning/good_thumbnails/'\n","\n","\n","file_list = os.listdir(folder_path)\n","\n","\n","for file_name in file_list:\n","\n","    image_path = os.path.join(folder_path, file_name)\n","\n","\n","    test_image = preprocess_image(image_path)\n","\n","\n","    test_image = np.expand_dims(test_image, axis=0)\n","\n","\n","    predictions = model.predict(test_image)\n","\n","    predicted_label = label_encoder.inverse_transform([round(predictions[0][0])])[0]\n","\n","    print(f'Image: {file_name}, Predicted Label: {predicted_label}')\n"],"metadata":{"id":"HRXuVKRJevnS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_data_folder = '/content/drive/MyDrive/Neural Network And Deep Learning/good_thumbnails/'\n","\n","\n","def preprocess_image_for_prediction(image_path, target_size=(224, 224)):\n","    image = cv2.imread(image_path)\n","    image = cv2.resize(image, target_size)\n","    image = image.astype('float32') / 255.0\n","    return image\n","\n","\n","new_data_images = [f for f in os.listdir(new_data_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","\n","model = build_and_compile_model()  # Replace with the actual path to your trained model\n","\n","\n","predictions = []\n","\n","for image_file in new_data_images:\n","    image_path = os.path.join(new_data_folder, image_file)\n","    processed_image = preprocess_image_for_prediction(image_path)\n","    processed_image = np.expand_dims(processed_image, axis=0)  # Add batch dimension\n","    prediction = model.predict(processed_image)\n","    predictions.append({'image_file': image_file, 'prediction': prediction[0][0]})\n","\n","for result in predictions:\n","    print(f\"Image: {result['image_file']}, Prediction: {result['prediction']}\")"],"metadata":{"id":"WvCfcnB1Opj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["advacned model - added learning rate and early stopping"],"metadata":{"id":"eJPxU_huUmSJ"}},{"cell_type":"code","source":["def preprocess_image_for_prediction(image_path, target_size=(224, 224)):\n","    image = cv2.imread(image_path)\n","    image = cv2.resize(image, target_size)\n","    image = image.astype('float32') / 255.0\n","    return image\n","\n","\n","\n","df_train_subsampled = df.sample(n=1000, random_state=42)  # Adjust the sample size as needed\n","\n","\n","df_train_subsampled['Processed_Image'] = df_train_subsampled['Image_Path'].apply(preprocess_image_for_prediction)\n","\n","\n","label_encoder = LabelEncoder()\n","df_train_subsampled['Encoded_Label'] = label_encoder.fit_transform(df_train_subsampled['Label'])\n","\n","\n","X_train_subsampled, X_val_subsampled, y_train_subsampled, y_val_subsampled = train_test_split(\n","    np.array(df_train_subsampled['Processed_Image'].tolist()),\n","    df_train_subsampled['Encoded_Label'],\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","# Data augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","# Build a model with improved architecture\n","def build_and_compile_model(input_shape=(224, 224, 3), num_classes=1):\n","    model = models.Sequential()\n","\n","    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(Dropout(0.2))\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(Dropout(0.2))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(num_classes, activation='sigmoid'))\n","\n","    # Compile the model\n","    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","    #model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","\n","model = build_and_compile_model()\n","\n","# Model callbacks\n","#early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n","tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1)\n","\n","# Train the model with data augmentation\n","history = model.fit(\n","    train_datagen.flow(X_train_subsampled, y_train_subsampled, batch_size=12),\n","    epochs=20,\n","    validation_data=(X_val_subsampled, y_val_subsampled),\n","    #callbacks=[early_stopping, model_checkpoint, tensorboard]\n","    callbacks=[model_checkpoint, tensorboard]\n",")\n","\n","# Evaluate the model on the test dataset\n","test_loss, test_accuracy = model.evaluate(X_val_subsampled, y_val_subsampled)\n","print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"],"metadata":{"id":"QeXlhjhPUl23","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702261686665,"user_tz":300,"elapsed":184069,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}},"outputId":"336e5ce0-36b6-4aa6-c65d-82062f29e3d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","67/67 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.7138"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r67/67 [==============================] - 10s 135ms/step - loss: 0.6122 - accuracy: 0.7138 - val_loss: 18.0622 - val_accuracy: 0.6800\n","Epoch 2/20\n","67/67 [==============================] - 9s 126ms/step - loss: 0.5919 - accuracy: 0.7188 - val_loss: 21.9407 - val_accuracy: 0.6800\n","Epoch 3/20\n","67/67 [==============================] - 9s 127ms/step - loss: 0.5952 - accuracy: 0.7188 - val_loss: 20.3575 - val_accuracy: 0.6800\n","Epoch 4/20\n","67/67 [==============================] - 8s 124ms/step - loss: 0.5984 - accuracy: 0.7188 - val_loss: 19.9008 - val_accuracy: 0.6800\n","Epoch 5/20\n","67/67 [==============================] - 8s 124ms/step - loss: 0.5856 - accuracy: 0.7188 - val_loss: 23.2931 - val_accuracy: 0.6800\n","Epoch 6/20\n","67/67 [==============================] - 9s 128ms/step - loss: 0.5825 - accuracy: 0.7188 - val_loss: 26.2197 - val_accuracy: 0.6800\n","Epoch 7/20\n","67/67 [==============================] - 8s 126ms/step - loss: 0.5872 - accuracy: 0.7188 - val_loss: 24.6862 - val_accuracy: 0.6800\n","Epoch 8/20\n","67/67 [==============================] - 9s 126ms/step - loss: 0.5841 - accuracy: 0.7188 - val_loss: 26.9037 - val_accuracy: 0.6800\n","Epoch 9/20\n","67/67 [==============================] - 9s 128ms/step - loss: 0.5806 - accuracy: 0.7188 - val_loss: 25.3387 - val_accuracy: 0.6800\n","Epoch 10/20\n","67/67 [==============================] - 8s 124ms/step - loss: 0.5780 - accuracy: 0.7188 - val_loss: 23.5937 - val_accuracy: 0.6800\n","Epoch 11/20\n","67/67 [==============================] - 9s 127ms/step - loss: 0.5744 - accuracy: 0.7188 - val_loss: 27.9692 - val_accuracy: 0.6800\n","Epoch 12/20\n","67/67 [==============================] - 8s 126ms/step - loss: 0.5781 - accuracy: 0.7188 - val_loss: 24.8905 - val_accuracy: 0.6800\n","Epoch 13/20\n","67/67 [==============================] - 8s 125ms/step - loss: 0.5742 - accuracy: 0.7188 - val_loss: 18.5435 - val_accuracy: 0.6800\n","Epoch 14/20\n","67/67 [==============================] - 8s 126ms/step - loss: 0.5724 - accuracy: 0.7188 - val_loss: 18.1175 - val_accuracy: 0.6800\n","Epoch 15/20\n","67/67 [==============================] - 9s 130ms/step - loss: 0.5793 - accuracy: 0.7188 - val_loss: 17.8793 - val_accuracy: 0.6800\n","Epoch 16/20\n","67/67 [==============================] - 9s 130ms/step - loss: 0.5678 - accuracy: 0.7188 - val_loss: 16.5311 - val_accuracy: 0.6800\n","Epoch 17/20\n","67/67 [==============================] - 9s 128ms/step - loss: 0.5621 - accuracy: 0.7188 - val_loss: 16.5358 - val_accuracy: 0.6800\n","Epoch 18/20\n","67/67 [==============================] - 9s 130ms/step - loss: 0.5667 - accuracy: 0.7188 - val_loss: 9.1256 - val_accuracy: 0.6800\n","Epoch 19/20\n","67/67 [==============================] - 9s 127ms/step - loss: 0.5652 - accuracy: 0.7188 - val_loss: 9.7391 - val_accuracy: 0.6800\n","Epoch 20/20\n","67/67 [==============================] - 8s 125ms/step - loss: 0.5578 - accuracy: 0.7188 - val_loss: 9.5377 - val_accuracy: 0.6800\n","7/7 [==============================] - 0s 15ms/step - loss: 9.5377 - accuracy: 0.6800\n","Test Loss: 9.537700653076172, Test Accuracy: 0.6800000071525574\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"eCpuzZpKUlyr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# vgg 16"],"metadata":{"id":"6qBsNBpyyYiA"}},{"cell_type":"code","source":["good_train_data_dir = '/content/drive/MyDrive/Neural Network And Deep Learning/validation_thumbnails/'\n","bad_train_data_dir = '/content/drive/MyDrive/Neural Network And Deep Learning/bad/'\n","random_test_data_dir = '/content/drive/MyDrive/Neural Network And Deep Learning/good_thumbnails/'"],"metadata":{"id":"_uucW0yXJv-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Subsample size for each dataset\n","subsample_size = 1000\n","\n","# Data augmentation and normalization\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","\n","good_images = []\n","good_labels = []\n","\n","for filename in os.listdir(good_train_data_dir):\n","    img = cv2.imread(os.path.join(good_train_data_dir, filename))\n","    img = cv2.resize(img, (224, 224))\n","    img = img / 255.0  # Normalize pixel values\n","    good_images.append(img)\n","    good_labels.append(1)  # Assign label 1 for 'good'\n","\n","bad_images = []\n","bad_labels = []\n","\n","for filename in os.listdir(bad_train_data_dir):\n","    img = cv2.imread(os.path.join(bad_train_data_dir, filename))\n","    img = cv2.resize(img, (224, 224))\n","    img = img / 255.0  # Normalize pixel values\n","    bad_images.append(img)\n","    bad_labels.append(0)  # Assign label 0 for 'bad'\n","\n","\n","good_images = np.array(good_images)\n","good_labels = np.array(good_labels)\n","bad_images = np.array(bad_images)\n","bad_labels = np.array(bad_labels)\n","\n","\n","all_images = np.concatenate([good_images, bad_images])\n","all_labels = np.concatenate([good_labels, bad_labels])\n","\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    all_images, all_labels, test_size=0.2, random_state=42)\n","\n"],"metadata":{"id":"wCLQIhaCK1-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random_test_images = []\n","random_test_labels = []\n","\n","for filename in os.listdir(random_test_data_dir):\n","    img = cv2.imread(os.path.join(random_test_data_dir, filename))\n","    img = cv2.resize(img, (224, 224))\n","    img = img / 255.0  # Normalize pixel values\n","    random_test_images.append(img)\n","    random_test_labels.append(0.5)\n","\n","random_test_images = np.array(random_test_images)\n","random_test_labels = np.array(random_test_labels)"],"metadata":{"id":"IDpib-CVOw1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","model = models.Sequential()\n","model.add(base_model)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model on 'good' and 'bad' datasets\n","model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val))\n","\n","# Evaluate the model on the random test dataset\n","test_loss, test_accuracy = model.evaluate(random_test_images, random_test_labels)\n","print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cx9P4mxeLGo_","executionInfo":{"status":"ok","timestamp":1702237735544,"user_tz":300,"elapsed":91666,"user":{"displayName":"Hanna Song","userId":"17115407596764586665"}},"outputId":"4b8ab0a0-3338-4ec9-acdc-75af2e08bf93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 2s 0us/step\n","Epoch 1/10\n","43/43 [==============================] - 25s 205ms/step - loss: 3.7395 - accuracy: 0.6972 - val_loss: 0.5875 - val_accuracy: 0.7214\n","Epoch 2/10\n","43/43 [==============================] - 6s 135ms/step - loss: 0.5890 - accuracy: 0.7397 - val_loss: 0.5833 - val_accuracy: 0.7214\n","Epoch 3/10\n","43/43 [==============================] - 6s 135ms/step - loss: 0.5671 - accuracy: 0.7397 - val_loss: 0.5615 - val_accuracy: 0.7214\n","Epoch 4/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5999 - accuracy: 0.7397 - val_loss: 0.5776 - val_accuracy: 0.7214\n","Epoch 5/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5811 - accuracy: 0.7405 - val_loss: 0.5777 - val_accuracy: 0.7214\n","Epoch 6/10\n","43/43 [==============================] - 6s 135ms/step - loss: 0.5691 - accuracy: 0.7412 - val_loss: 0.5751 - val_accuracy: 0.7214\n","Epoch 7/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5668 - accuracy: 0.7412 - val_loss: 0.6129 - val_accuracy: 0.7214\n","Epoch 8/10\n","43/43 [==============================] - 6s 135ms/step - loss: 0.5462 - accuracy: 0.7397 - val_loss: 0.5269 - val_accuracy: 0.7331\n","Epoch 9/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5316 - accuracy: 0.7427 - val_loss: 0.5409 - val_accuracy: 0.7243\n","Epoch 10/10\n","43/43 [==============================] - 6s 136ms/step - loss: 0.5287 - accuracy: 0.7478 - val_loss: 0.5240 - val_accuracy: 0.7331\n","62/62 [==============================] - 4s 54ms/step - loss: 0.7522 - accuracy: 0.0000e+00\n","Test Loss: 0.752239465713501, Test Accuracy: 0.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gi6isiXIPQQs"},"execution_count":null,"outputs":[]}]}